import streamlit as st
import pandas as pd
import os
import numpy as np
from src.ui import UI
from datetime import datetime, timedelta
from src.settings import verify_password
from src.data import Naver
from src.chart import Chart
from threading import Thread, Lock
import time

naver = Naver()

# ê°œë°œ ëª¨ë“œì¼ ë•Œ ìºì‹œ ì´ˆê¸°í™”
if os.environ.get('STREAMLIT_DEVELOPMENT', 'false').lower() == 'true':
    st.cache_data.clear()
    st.cache_resource.clear()

def verify_user_password():
    """ì‚¬ìš©ì ë¹„ë°€ë²ˆí˜¸ ê²€ì¦ ì²˜ë¦¬"""
    st.session_state.setdefault('password_verified', False)
    st.session_state.setdefault('password_error', False)
    
    def check_password():
        password = st.session_state.review_password_input
        st.session_state.password_verified = verify_password(password)
        st.session_state.password_error = not st.session_state.password_verified
    
    if not st.session_state.password_verified:
        st.subheader("ğŸ”’ ê´€ë¦¬ì ë¡œê·¸ì¸")
        UI().create_password_input(
            on_change_callback=check_password,
            has_error=st.session_state.password_error,
            key="review_password_input"
        )
        return False
    return True

def load_pension_data():
    """íœì…˜ ê¸°ë³¸ ì •ë³´ ë¡œë“œ"""
    pension_info = pd.read_csv('./static/database/pension_info.csv')
    pension_info = pension_info[['businessName', 'channelId', 'addressNew']].drop_duplicates()
    pension_info['channelId'] = pension_info['channelId'].astype(str)
    return pension_info

def fetch_rating_data_threaded(pension_info_filtered):
    """ë©€í‹°ìŠ¤ë ˆë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬ë·° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    # Naver ê°ì²´ ìƒì„±
    naver = Naver()
    
    # ë¡œë”© ìƒíƒœ í‘œì‹œ
    status_text = st.empty()
    progress_bar = st.progress(0)
    
    # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸ ë° ë½
    all_results = []
    results_lock = Lock()
    
    # ì§„í–‰ ìƒí™© ì¶”ì ìš© ë³€ìˆ˜
    total_pensions = len(pension_info_filtered)
    completed_count = 0
    completed_lock = Lock()
    
    # ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰ë  í•¨ìˆ˜
    def fetch_rating_worker(row):
        nonlocal completed_count
        
        channel_id = row.channelId
        business_name = row.businessName
        
        try:
            # ë¦¬ë·° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            result = naver._get_rating_playwright(channel_id)
            
            # ê²°ê³¼ê°€ ë°ì´í„°í”„ë ˆì„ì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(result, pd.DataFrame):
                result['businessName'] = business_name
                result['channelId'] = channel_id
                
                # ë½ì„ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ì— ì•ˆì „í•˜ê²Œ ì¶”ê°€
                with results_lock:
                    all_results.append(result)
            else:
                print(f"ì˜¤ë¥˜: {business_name}ì˜ ë¦¬ë·° ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ")
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {business_name} - {str(e)}")
        
        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        with completed_lock:
            completed_count += 1
            progress = completed_count / total_pensions
            progress_bar.progress(progress)
            status_text.text(f"ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ({completed_count}/{total_pensions})")
    
    # ìŠ¤ë ˆë“œ ìƒì„± ë° ì‹¤í–‰
    threads = []
    max_workers = min(5, total_pensions)  # ìµœëŒ€ 5ê°œ ìŠ¤ë ˆë“œë¡œ ì œí•œ
    
    for row in pension_info_filtered.itertuples(index=False):
        t = Thread(target=fetch_rating_worker, args=(row,))
        threads.append(t)
        t.start()
        
        # ìµœëŒ€ ë™ì‹œ ì‹¤í–‰ ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ
        active_threads = sum(1 for t in threads if t.is_alive())
        while active_threads >= max_workers:
            time.sleep(0.1)  # ì ì‹œ ëŒ€ê¸°
            active_threads = sum(1 for t in threads if t.is_alive())
    
    # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    for t in threads:
        t.join()
    
    # ì§„í–‰ ìƒí™© ë°” ë° ìƒíƒœ í…ìŠ¤íŠ¸ ì œê±°
    progress_bar.empty()
    status_text.empty()
    
    # ê²°ê³¼ ë³‘í•©
    rating_data = pd.DataFrame()
    if all_results:
        rating_data = pd.concat(all_results, ignore_index=True)
        
        # CSVë¡œ ì €ì¥
        rating_data.to_csv('./static/database/rating_data.csv', index=False)
    
    return rating_data

def process_rating_data(rating_data, pension_info_filtered):
    """ë¦¬ë·° ë°ì´í„° ì²˜ë¦¬ ë° Z-score ê³„ì‚°"""
    # ë°ì´í„° íƒ€ì… ë³€í™˜
    rating_data['channelId'] = rating_data['channelId'].astype(str)
    pension_info_filtered['channelId'] = pension_info_filtered['channelId'].astype(str)
    
    # ë°ì´í„° ë³‘í•©
    merged_data = pd.merge(
        rating_data,
        pension_info_filtered[['channelId', 'businessName']],
        on='channelId',
        how='left'
    )
    
    # í‰ì  ë°ì´í„° ì „ì²˜ë¦¬
    merged_data['rating'] = pd.to_numeric(merged_data['rating'], errors='coerce')
    merged_data = merged_data.dropna(subset=['rating'])
    
    # ê·¸ë£¹í™” ì»¬ëŸ¼ ê²°ì •
    group_cols = ['channelId', 'businessName', 'review_item'] if 'businessName' in merged_data.columns else ['channelId', 'review_item']
    pension_col = 'businessName' if 'businessName' in merged_data.columns else 'pension_name'
    
    if pension_col == 'pension_name':
        pension_mapping = dict(zip(
            pension_info_filtered['channelId'],
            pension_info_filtered['businessName']
        ))
        merged_data['pension_name'] = merged_data['channelId'].map(pension_mapping)
        group_cols = ['channelId', 'pension_name', 'review_item']
    
    # í‰ê·  í‰ì  ê³„ì‚°
    rating_average = merged_data.groupby(group_cols)['rating'].mean().reset_index()
    pension_totals = rating_average.groupby(['channelId', pension_col])['rating'].sum().reset_index()
    pension_totals.rename(columns={'rating': 'total_rating'}, inplace=True)
    
    # ë°ì´í„° ë³‘í•© ë° ìƒëŒ€ê°’ ê³„ì‚°
    rating_average = pd.merge(
        rating_average,
        pension_totals,
        on=['channelId', pension_col],
        how='left'
    )
    
    # ìƒëŒ€ê°’ ê³„ì‚°
    rating_average['rating_relative'] = rating_average['rating'] / rating_average['total_rating']
    rating_average['rating_relative_pct'] = rating_average['rating_relative'] * 100
    
    # Z-score ê³„ì‚°
    zscore_data = []
    for pension_name in rating_average[pension_col].unique():
        pension_data = rating_average[rating_average[pension_col] == pension_name].copy()
        mean_score = pension_data['rating_relative_pct'].mean()
        std_score = pension_data['rating_relative_pct'].std()
        pension_data['zscore'] = (pension_data['rating_relative_pct'] - mean_score) / std_score if std_score != 0 else 0
        zscore_data.append(pension_data)
    
    return pd.concat(zscore_data), pension_col

def prioritize_cafeian(rating_average, pension_col):
    """ì¹´í˜ì´ì•ˆì„ ì²« ë²ˆì§¸ë¡œ í•˜ëŠ” íœì…˜ ìˆœì„œ ìƒì„± ë° ì ìš©"""
    pension_order = list(rating_average[pension_col].unique())
    
    # ì¹´í˜ì´ì•ˆ íœì…˜ ì‹ë³„ (ì¹´í˜ì´ì•ˆ ë˜ëŠ” ì¹´í˜ ì´ì•ˆ)
    cafeian_pensions = [p for p in pension_order if 'ì¹´í˜ì´ì•ˆ' in p or 'ì¹´í˜ ì´ì•ˆ' in p]
    
    if cafeian_pensions:
        # ì¹´í˜ì´ì•ˆ íœì…˜ë“¤ì„ ëª¨ë‘ ì œê±°í•˜ê³  ë§¨ ì•ì— ì¶”ê°€
        for cafeian in cafeian_pensions:
            pension_order.remove(cafeian)
        pension_order = cafeian_pensions + sorted(pension_order)
    else:
        pension_order = sorted(pension_order)
    
    # íœì…˜ ì—´ì„ ì¹´í…Œê³ ë¦¬ íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ê³  ìˆœì„œ ì§€ì •
    rating_average[pension_col] = pd.Categorical(
        rating_average[pension_col],
        categories=pension_order,
        ordered=True
    )
    
    # ì •ë ¬ëœ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
    return rating_average.sort_values(pension_col), pension_order

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    st.session_state.setdefault('chart_type', "radar")
    st.session_state.setdefault('has_analysis_result', False)
    st.session_state.setdefault('rating_data_dict', None)
    st.session_state.setdefault('rating_average_dict', None)
    st.session_state.setdefault('pension_col_result', None)
    st.session_state.setdefault('analyzed_pensions', [])

def handle_logout():
    """ë¡œê·¸ì•„ì›ƒ ì²˜ë¦¬"""
    if st.button("ë¡œê·¸ì•„ì›ƒ", key="review_logout", type="secondary"):
        st.session_state.password_verified = False
        st.rerun()

def show_review_analysis_page():
    """ë¦¬ë·° ë¶„ì„ í˜ì´ì§€ ë©”ì¸ í•¨ìˆ˜"""
    # ë¹„ë°€ë²ˆí˜¸ ê²€ì¦
    if not verify_user_password():
        return
    
    # í˜ì´ì§€ ì œëª© & ë¡œê·¸ì•„ì›ƒ ë²„íŠ¼
    col1, col2 = st.columns([5, 1])
    with col1:
        st.subheader("ğŸ” íœì…˜ ë¦¬ë·° ë¹„êµ")
    with col2:
        handle_logout()
    
    # ê¸°ë³¸ ë°ì´í„° ë¡œë“œ
    pension_info = load_pension_data()
    
    # íœì…˜ ì„ íƒ UI (ì¹´í˜ì´ì•ˆ ì œì™¸)
    all_pensions = pension_info['businessName'].unique()
    
    # ì¹´í˜ì´ì•ˆ íœì…˜ ì‹ë³„
    cafeian_pensions = [p for p in all_pensions if 'ì¹´í˜ì´ì•ˆ' in p or 'ì¹´í˜ ì´ì•ˆ' in p]
    
    # ì¹´í˜ì´ì•ˆì„ ì œì™¸í•œ ë‹¤ë¥¸ íœì…˜ë“¤ë§Œ ì„ íƒ ì˜µì…˜ìœ¼ë¡œ í‘œì‹œ
    other_pensions = [p for p in all_pensions if p not in cafeian_pensions]
    
    selected_pensions = st.multiselect(
        "íœì…˜ ì„ íƒ (ìµœëŒ€ 5ê°œ, ì¹´í˜ì´ì•ˆì€ ìë™ í¬í•¨)",
        options=other_pensions,
        default=other_pensions[:5],  # ìµœëŒ€ 5ê°œ ê¸°ë³¸ ì„ íƒ
        key="review_selected_pensions",
        max_selections=5
    )
    
    # ë¶„ì„ì„ ìœ„í•´ ì¹´í˜ì´ì•ˆì„ ì„ íƒëœ íœì…˜ ëª©ë¡ì— ì¶”ê°€
    analysis_pensions = cafeian_pensions + selected_pensions
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    col1,col2, col3 = st.columns([1,1,1])
    with col2:
        # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
        review_button = st.button(
            "ë¶„ì„ ì‹œì‘", 
            use_container_width=True, 
            key=f"analyze_button_{st.session_state.review_selected_pensions}",
            type="primary"
        )
    
    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ ì¡°ê±´
    if not (review_button or st.session_state.has_analysis_result):
        return
    
    # ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„
    if review_button:
        # ì„ íƒí•œ íœì…˜ ì •ë³´ í‘œì‹œ (ì¹´í˜ì´ì•ˆ í¬í•¨)
        pension_info_filtered = pension_info[pension_info['businessName'].isin(analysis_pensions)]
        st.dataframe(pension_info_filtered, use_container_width=True, hide_index=True)
        
        # ë¦¬ë·° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        with st.spinner("ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘ì¤‘..."):
            try:
                # ìŠ¤ë ˆë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬ë·° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                rating_data = fetch_rating_data_threaded(pension_info_filtered)
                
                # ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬
                if rating_data is None or rating_data.empty:
                    st.error("ë¦¬ë·° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return
                
                # ì„¸ì…˜ ìƒíƒœì— ë°ì´í„° ì €ì¥
                st.session_state.rating_data = rating_data
                st.session_state.pension_info_filtered = pension_info_filtered
            except Exception as e:
                st.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                return
        
        # ë°ì´í„° ë¶„ì„
        with st.spinner("ë¦¬ë·° ë°ì´í„° ë¶„ì„ì¤‘..."):
            rating_average, pension_col = process_rating_data(rating_data, pension_info_filtered)
            
            # ë¶„ì„ ê²°ê³¼ ì €ì¥
            st.session_state.rating_average = rating_average
            st.session_state.pension_col = pension_col
            st.session_state.has_analysis_result = True
            
            # ì¹´í…Œê³ ë¦¬ ìˆœì„œ ì •ì˜
            st.session_state.category_order = rating_average['review_item'].unique().tolist()
    
    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if st.session_state.has_analysis_result:
        rating_average = st.session_state.rating_average
        pension_col = st.session_state.pension_col
        
        # ì¹´í˜ì´ì•ˆì„ ìµœìƒìœ„ë¡œ ì •ë ¬
        rating_average, pension_order = prioritize_cafeian(rating_average, pension_col)
        
        # ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
        Chart.show_rating_charts(rating_average, pension_col, st.session_state.category_order)

if __name__ == "__main__":
    show_review_analysis_page() 